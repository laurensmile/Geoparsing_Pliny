{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29b19f3",
   "metadata": {},
   "source": [
    "```sentences_NH/engbook37``` is an input file being referenced here, but I don't have, nor do I have a script that generates it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283b578",
   "metadata": {},
   "source": [
    "Using the Vecalign script vecalign.py (partially modified) from https://github.com/thompsonb/vecalign, the code takes as input the originary files containing the sentences, the overlap files, the files containing the embeddings. The output of the alignment is a list of indexes pairs and a float number with the compute of the alignment cost.\n",
    "\n",
    "The modification of the vecalign.py file consists in generating a .TXT file containing the output of the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baddcaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use latest conda\n",
    "# !conda update conda -y\n",
    "# # Create conda environment\n",
    "# !conda create  --force -y --name vecalign python=3.7\n",
    "# # Activate new environment\n",
    "# !source `conda info --base`/etc/profile.d/conda.sh # See: https://github.com/conda/conda/issues/7980\n",
    "# !conda activate vecalign\n",
    "# # Install required packages\n",
    "# !conda install -y -c anaconda cython\n",
    "# !conda install -y -c anaconda numpy\n",
    "# !pip install mcerp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d2c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate overlaps file using the eng and lat sentences in the sentences_NH folder\n",
    "# !python overlap.py -i sentences_NH/engbook37 -o sentences_NH/engoverlaps37.eng -n 10\n",
    "# !python overlap.py -i sentences_NH/latbook37 -o sentences_NH/latoverlaps37.lat -n 10\n",
    "\n",
    "#we do not use shell calls any more. We import the overlap utility and call the go function. \n",
    "#this function is normally called whenever the user performs the command above\n",
    "#Inside the overlap utility the go function is a redundant copy of make_overlap(), we call that \n",
    "#without retaing go for maintainability. \n",
    "#we call make_overlap with arguments: inputfile, outputfile, numberoverlaps\n",
    "#TODO: make parameters dynamic!\n",
    "#   replaced by conten in next cell\n",
    "# from utils import overlap\n",
    "# overlap.make_overlap('sentences_NH/engbook37', 'sentences_NH/engoverlaps37.eng', 10)\n",
    "# overlap.make_overlap('sentences_NH/latbook37', 'sentences_NH/latoverlaps37.lat', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263ea145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:02<00:00, 14.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import overlap\n",
    "from utils.dp_core import *\n",
    "from setuptools import distutils  #TODO required?\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from utils import vecalign\n",
    "\n",
    "#TODO: make parameters dynamic\n",
    "#TODO: discuss with Laura; where are the source files?\n",
    "#       the target file is created by the overlap utility; does not need to exist.\n",
    "#       BUT, we need to know what it is used for!\n",
    "\n",
    "for i in tqdm(range(1,38)): \n",
    "    overlap.make_overlap(source = 'data/intermediate/books/engbook'+str(i), \n",
    "                     target = 'data/intermediate/books/engoverlaps'+str(i)+'.eng', \n",
    "                     num_overlaps = 10\n",
    "                     )\n",
    "    overlap.make_overlap(source = 'data/intermediate/books/latbook'+str(i), \n",
    "                     target = 'data/intermediate/books/latoverlaps'+str(i)+'.lat', \n",
    "                     num_overlaps = 10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f35cfef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2247d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workdir\\MyApps\\Python_VENV\\geoparsing_naturalhistory-main\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Workdir\\MyApps\\Python_VENV\\geoparsing_naturalhistory-main\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## import the S-BERT Python library sentence_transformer\n",
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ca34d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engoverlaps1.eng\n",
      "engoverlaps10.eng\n",
      "data/intermediate/books/engoverlaps10.eng\n",
      "data/intermediate/books/latoverlaps10.lat\n",
      "Skipping creation of overlaps.eng.10.LaBSE.emb. Embeddings exist and cell is in no-ovverride mode.\n",
      "Skipping creation of overlaps.lat.10.LaBSE.emb. Embeddings exist and cell is in no-ovverride mode.\n",
      "engoverlaps11.eng\n",
      "data/intermediate/books/engoverlaps11.eng\n",
      "data/intermediate/books/latoverlaps11.lat\n",
      "making english embeddings: 9276\n",
      "making latin embeddings: 10026\n",
      "engoverlaps12.eng\n",
      "data/intermediate/books/engoverlaps12.eng\n",
      "data/intermediate/books/latoverlaps12.lat\n",
      "making english embeddings: 4211\n",
      "making latin embeddings: 4536\n",
      "engoverlaps13.eng\n",
      "data/intermediate/books/engoverlaps13.eng\n",
      "data/intermediate/books/latoverlaps13.lat\n",
      "making english embeddings: 3771\n",
      "making latin embeddings: 4156\n",
      "engoverlaps14.eng\n",
      "data/intermediate/books/engoverlaps14.eng\n",
      "data/intermediate/books/latoverlaps14.lat\n",
      "making english embeddings: 3786\n",
      "making latin embeddings: 4156\n"
     ]
    }
   ],
   "source": [
    "##CONFIG:\n",
    "#when set to True this will redo the labse files even if they exists.\n",
    "#when set to False, LABSE files will be retained, a new model won't be made.\n",
    "renew_labse_files = False\n",
    "\n",
    "basedir = 'data/intermediate/books'\n",
    "lang1 = 'eng'\n",
    "lang2 = 'lat'\n",
    "\n",
    "files = os.listdir(basedir)\n",
    "# Filtering only the files.\n",
    "files = [f for f in files if os.path.isfile(basedir+'/'+f) and f.strip().endswith(lang1)]\n",
    "\n",
    "#prepare a typle of embeddings with per tuple the Source and Target\n",
    "all_embeddings = []\n",
    "\n",
    "# for i in range(1,38):    \n",
    "for i in files:    \n",
    "    print(i)\n",
    "    #skip book 1: this is only the preface. Nothing expected there. \n",
    "    if i.endswith('s1.eng'): \n",
    "        continue\n",
    "    \n",
    "    ## get the eng overlap file\n",
    "    # path = \"/Users/u0154817/OneDrive - KU Leuven/Desktop/sentences_NH/engoverlaps\"+str(i)+'.eng'\n",
    "    path = basedir+'/'+i\n",
    "    print(path)\n",
    "    with open(path, \"r\", encoding=\"utf8\") as engfile:\n",
    "        overlap_sentences_eng = []\n",
    "        for line in engfile: ## create a list of the overlap eng sentences\n",
    "            overlap_sentences_eng.append(line)\n",
    "    \n",
    "    ## get the lat overlap file\n",
    "    path = path.replace('engoverlaps', 'latoverlaps')\n",
    "    path = path.replace('.eng', '.lat')\n",
    "    print(path)\n",
    "    with open(path, \"r\", encoding=\"utf8\") as latfile:\n",
    "        overlap_sentences_lat = []\n",
    "        for line in latfile:  ## create a list of the overlap lat sentences\n",
    "            overlap_sentences_lat.append(line)\n",
    "    ## generate the name of the LABSE files: \n",
    "    j = i.split('.')[0]\n",
    "    j = j.replace('engoverlaps', '').strip()\n",
    "    src_embedded_filename = 'overlaps.'+lang1+'.'+j+'.LaBSE.emb'\n",
    "    tgt_embedded_filename = 'overlaps.'+lang2+'.'+j+'.LaBSE.emb'\n",
    "    # if the files exist, do not override them:\n",
    "    engoverlap_missing = not os.path.exists('data/intermediate/labse_embeddings/overlaps.eng.'+str(j)+'.LaBSE.emb')\n",
    "    latoverlap_missing = not os.path.exists('data/intermediate/labse_embeddings/overlaps.lat.'+str(j)+'.LaBSE.emb')\n",
    "    ## generate the embeddings of the eng and lat overlap sentences (conditionally)\n",
    "    if renew_labse_files or engoverlap_missing: \n",
    "        print(f'making english embeddings: {len(overlap_sentences_eng)}')\n",
    "        overlaps_embeddings_eng_LaBSE = model.encode(overlap_sentences_eng)\n",
    "        overlaps_embeddings_eng_LaBSE.tofile('data/intermediate/labse_embeddings/overlaps.eng.'+str(j)+'.LaBSE.emb')\n",
    "    else:\n",
    "        print('Skipping creation of '+src_embedded_filename+'. Embeddings exist and cell is in no-ovverride mode.')\n",
    "    if renew_labse_files or latoverlap_missing:\n",
    "        print(f'making latin embeddings: {len(overlap_sentences_lat)}')\n",
    "        overlaps_embeddings_lat_LaBSE = model.encode(overlap_sentences_lat)\n",
    "        overlaps_embeddings_lat_LaBSE.tofile('data/intermediate/labse_embeddings/overlaps.lat.'+str(j)+'.LaBSE.emb')\n",
    "    else:\n",
    "        print('Skipping creation of '+tgt_embedded_filename+'. Embeddings exist and cell is in no-ovverride mode.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d67fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "dir = os.getcwd()\n",
    "os.path.join(dir, 'data', 'intermediate', 'books', 'engbook10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: here you'll need to create a forloop that iterates over all labse_embeddings files. \n",
    "# categorize them in latin and english ambeddings\n",
    "# link them by the number in their name\n",
    "# then run the linked versions in the vecalign_custom method.\n",
    "i = os.path.join(dir, 'data', 'intermediate', 'books', 'engbook10')\n",
    "path = os.path.join(dir, 'data', 'intermediate', 'books', 'latbook10')\n",
    "src_embedded_filename = 'data/intermediate/labse_embeddings/overlaps.eng.10.LaBSE.emb'\n",
    "tgt_embedded_filename = 'data/intermediate/labse_embeddings/overlaps.lat.10.LaBSE.emb'\n",
    "\n",
    "\n",
    "vecalign.vecalign_custom(\n",
    "        src=i, \n",
    "        tgt=path, \n",
    "        src_embed=('data/intermediate/books/engoverlaps10.eng', src_embedded_filename), \n",
    "        tgt_embed=('data/intermediate/books/latoverlaps10.lat', tgt_embedded_filename) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1fd86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## calculate the sentence similarity using the sentence files, the overlap files, and the sentence embeddings\n",
    "# !python vecalign.py --alignment_max_size 8 --src sentences_NH/engbook37 --tgt sentences_NH/latbook37 \\\n",
    "#    --src_embed sentences_NH/engoverlaps37.eng sentences_NH/overlaps.eng.37.LaBSE.emb  \\\n",
    "#    --tgt_embed sentences_NH/latoverlaps37.lat sentences_NH/overlaps.lat.37.LaBSE.emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0136c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vecalign(\n",
    "#     src='sentences_NH/engbook37', \n",
    "#     tgt='sentences_NH/latbook37', \n",
    "#       src_embed and tgt_embed have to become tuples: \n",
    "#       first is a text file, second is a binary embeddings file\n",
    "#     src_embed='sentences_NH/engoverlaps37.eng sentences_NH/overlaps.eng.37.LaBSE.emb', \n",
    "#     tgt_embed='sentences_NH/latoverlaps37.lat sentences_NH/overlaps.lat.37.LaBSE.emb'\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
