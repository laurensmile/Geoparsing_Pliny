{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73f9e52",
   "metadata": {},
   "source": [
    "The original code uses the following iterator: ``` #for book_n in range(1,38): ## for each book ``` to navigate through 37 different books. These files are generated using the step 4 notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa56e64",
   "metadata": {},
   "source": [
    "The code comes from a partially modified version of the SimAlign script available here: https://github.com/cisnlp/simalign/blob/master/simalign/simalign.py\n",
    "\n",
    "The UGARIT/grc-alignment model (https://huggingface.co/UGARIT/grc-alignment), a XML-ROBERTa-based language model, fine-tuned for the automatic alignment of multilingual texts at the word level.\n",
    "\n",
    "The projection consists in the transfer of the loc_id from the English token to the Latin token. IOB labels are not projected since the position of the tokens can differ between the English and the Latin sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265efabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d55217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Workdir\\MyApps\\Python_VENV\\geoparsing_naturalhistory-main\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, XLMRobertaModel, XLMRobertaTokenizer, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1e16fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Workdir\\MyApps\\Python_VENV\\geoparsing_naturalhistory-main\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at UGARIT/grc-alignment were not used when initializing XLMRobertaForMaskedLM: ['psi_cls.bias', 'psi_cls.decoder.weight', 'psi_cls.transform.bias', 'psi_cls.transform.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForMaskedLM(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): XLMRobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=250002, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"UGARIT/grc-alignment\"\n",
    "device=torch.device('cpu')\n",
    "layer: int=8\n",
    "distortion: float = 0.0\n",
    "\n",
    "config = AutoConfig.from_pretrained(model, output_hidden_states=True)\n",
    "emb_model = AutoModelForMaskedLM.from_pretrained(model, config=config)\n",
    "emb_model.eval()\n",
    "emb_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f65103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec54b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the function to get the word embeddings\n",
    "def get_embed_list(sent_batch) -> torch.Tensor:\n",
    "        if emb_model is not None:\n",
    "            with torch.no_grad():\n",
    "                if not isinstance(sent_batch[0], str):\n",
    "                    inputs = tokenizer(sent_batch, is_split_into_words=True, padding=True, truncation=True, return_tensors=\"pt\") ## tokenize the sentence\n",
    "                else:\n",
    "                    inputs = tokenizer(sent_batch, is_split_into_words=False, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "                hidden = emb_model(**inputs.to(device))[\"hidden_states\"]  ## create the embeddings\n",
    "                if layer >= len(hidden):\n",
    "                    raise ValueError(f\"Specified to take embeddings from layer {layer}, but model has only {len(hidden)} layers.\")\n",
    "                outputs = hidden[layer]\n",
    "                return outputs[:, 1:-1, :]\n",
    "        else:\n",
    "            return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b7f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the function to get the similarity matrix\n",
    "def get_similarity(X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "    return (cosine_similarity(X, Y) + 1.0) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68bb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the function to calculate the itermax matching method\n",
    "def iter_max(sim_matrix: np.ndarray, max_count: int=2) -> np.ndarray:\n",
    "    alpha_ratio = 0.9\n",
    "    m, n = sim_matrix.shape\n",
    "    forward = np.eye(n)[sim_matrix.argmax(axis=1)]  # m x n\n",
    "    backward = np.eye(m)[sim_matrix.argmax(axis=0)]  # n x m\n",
    "    inter = forward * backward.transpose()\n",
    "\n",
    "    if min(m, n) <= 2:\n",
    "        return inter\n",
    "\n",
    "    new_inter = np.zeros((m, n))\n",
    "    count = 1\n",
    "    while count < max_count:\n",
    "        mask_x = 1.0 - np.tile(inter.sum(1)[:, np.newaxis], (1, n)).clip(0.0, 1.0)\n",
    "        mask_y = 1.0 - np.tile(inter.sum(0)[np.newaxis, :], (m, 1)).clip(0.0, 1.0)\n",
    "        mask = ((alpha_ratio * mask_x) + (alpha_ratio * mask_y)).clip(0.0, 1.0)\n",
    "        mask_zeros = 1.0 - ((1.0 - mask_x) * (1.0 - mask_y))\n",
    "        if mask_x.sum() < 1.0 or mask_y.sum() < 1.0:\n",
    "            mask *= 0.0\n",
    "            mask_zeros *= 0.0\n",
    "\n",
    "        new_sim = sim_matrix * mask\n",
    "        fwd = np.eye(n)[new_sim.argmax(axis=1)] * mask_zeros\n",
    "        bac = np.eye(m)[new_sim.argmax(axis=0)].transpose() * mask_zeros\n",
    "        new_inter = fwd * bac\n",
    "\n",
    "        if np.array_equal(inter + new_inter, inter):\n",
    "                break\n",
    "        inter = inter + new_inter\n",
    "        count += 1\n",
    "        \n",
    "    return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5aafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open the CSV file containing the eng text\n",
    "NH_eng_sentences = pd.read_csv(r\"data/intermediate/NH_eng_groupedsentences.csv\")\n",
    "## open the CSV file containing the lat text\n",
    "NH_lat_sentences = pd.read_csv(r\"data/intermediate/NH_lat_groupedsentences.csv\", dtype={'reference': 'str'})\n",
    "NH_lat_sentences['loc_ent_id'] = '-' ## the column will contain the id of the LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d918f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r\"data/intermediate/alignment\"\n",
    "#pattern = '\\[(\\d+(?:,\\s*\\d+)*)\\](?:,\\s*\\[(\\d+(?:,\\s*\\d+)*)\\])?.*$'\n",
    "#convert the pattern to a raw string, more clear\n",
    "pattern = r'\\[(\\d+(?:,\\s*\\d+)*)\\](?:,\\s*\\[(\\d+(?:,\\s*\\d+)*)\\])?.*$'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad139e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2715909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/intermediate/alignment 1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/intermediate/alignment1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m filter_book_lat \u001b[38;5;241m=\u001b[39m NH_lat_sentences[NH_lat_sentences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m book_n] \u001b[38;5;66;03m## select the tokens in the lat book//\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(file_name)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file: \u001b[38;5;66;03m## open the file containing the sentence alignments for the eng and lat book\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file: \u001b[38;5;66;03m## for each alignment\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         match1 \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(pattern,line) \u001b[38;5;66;03m## get the index pair of the alignment\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Workdir\\MyApps\\Python_VENV\\geoparsing_naturalhistory-main\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/intermediate/alignment1.txt'"
     ]
    }
   ],
   "source": [
    "#you need to have the vecalign utility ran before you can do this step!\n",
    "\n",
    "#for book_n in range(1,38): ## for each book\n",
    "for book_n, df in NH_eng_sentences.groupby('book'): \n",
    "    print(path, book_n)\n",
    "    #TODO: use these alignment files: C:\\Workdir\\MyApps\\Python_VENV\\geoparsing_naturalhistory-main\\data\\intermediate\\alignments\n",
    "    file_name = path+str(book_n)+'.txt' \n",
    "    \n",
    "    filter_book_eng = df #NH_eng_sentences[NH_eng_sentences['book'] == book_n] ## select the tokens in the eng book\n",
    "    filter_book_lat = NH_lat_sentences[NH_lat_sentences['book'] == book_n] ## select the tokens in the lat book//\n",
    "\n",
    "    # print(file_name)\n",
    "    with open(file_name, \"r\") as file: ## open the file containing the sentence alignments for the eng and lat book\n",
    "        \n",
    "        for line in file: ## for each alignment\n",
    "            match1 = re.search(pattern,line) ## get the index pair of the alignment\n",
    "            index_eng = match1[1] ## get the index(es) of the english sentence(s)\n",
    "            index_lat = match1[2] ## get the index(es) of the latin sentence(s)\n",
    "            \n",
    "            if index_eng and index_lat: ## if an alignment was found\n",
    "                index_eng = index_eng.split(',') ## if there is more than one index, split them\n",
    "                index_eng = [int(i) for i in index_eng]\n",
    "                filter_sentence_eng = filter_book_eng[filter_book_eng['sentence'].isin(index_eng)] ## select all the tokens in the corresponding sentence(s)\n",
    "                filter_sentence_eng = filter_sentence_eng.reset_index()\n",
    "                                                       \n",
    "                src_sent = []\n",
    "                indexes_to_project = []\n",
    "                loc_ent_ids = []\n",
    "                \n",
    "                for i, engtoken in enumerate(filter_sentence_eng['token']): ## for each token\n",
    "                    src_sent.append(engtoken) ## list the tokens of the source eng sentence\n",
    "                    loc_ent_ids.append(filter_sentence_eng['loc_ent_id'][i]) ## list the loc_ent_id for each token\n",
    "                    \n",
    "                    if 'LOC' in filter_sentence_eng['flair_ner'][i]: ## if the token is a LOC entity\n",
    "                        indexes_to_project.append(i) ## keep the index\n",
    "                \n",
    "                if len(indexes_to_project) > 0: ## if the sentence contains a LOC entity\n",
    "                                        \n",
    "                    index_lat = index_lat.split(',')\n",
    "                    index_lat = [int(i) for i in index_lat]\n",
    "                    filter_sentence_lat = filter_book_lat[filter_book_lat['sentence'].isin(index_lat)]\n",
    "                    filter_sentence_lat = filter_sentence_lat.reset_index()\n",
    "                    \n",
    "                    trg_sent = []\n",
    "                    indexes_to_update = []\n",
    "                    \n",
    "                    for i, lattoken in enumerate(filter_sentence_lat['token']):\n",
    "                        trg_sent.append(lattoken)  ## list the tokens of the target lat sentence\n",
    "                        indexes_to_update.append(filter_sentence_lat['level_0'][i]) ## index of the token in the NH_lat_sentences dataframe\n",
    "                    \n",
    "                    ## perform the word alignment (code revisited from SimAlign)\n",
    "                    \n",
    "                    l1_tokens = [tokenizer.tokenize(word) for word in src_sent] \n",
    "                    l2_tokens = [tokenizer.tokenize(word) for word in trg_sent] \n",
    "                    bpe_lists = [[bpe for w in sent for bpe in w] for sent in [l1_tokens, l2_tokens]]\n",
    "    \n",
    "                    l1_b2w_map = []\n",
    "                    for i, wlist in enumerate(l1_tokens):\n",
    "                        l1_b2w_map += [i for x in wlist]\n",
    "    \n",
    "                    l2_b2w_map = []\n",
    "                    for i, wlist in enumerate(l2_tokens):\n",
    "                        l2_b2w_map += [i for x in wlist]\n",
    "                    \n",
    "                    vectors = get_embed_list([src_sent, trg_sent]).cpu().detach().numpy()\n",
    "                    vectors = [vectors[i, :len(bpe_lists[i])] for i in [0, 1]]\n",
    "\n",
    "                    all_mats = {} ## create a dictionary\n",
    "                    sim = get_similarity(vectors[0], vectors[1]) ## get the cosine similarity\n",
    "                    all_mats[\"itermax\"] = iter_max(sim) ## generate a key-value\n",
    "                    aligns = {} ## create a dictionary\n",
    "                    aligns['itermax'] = set()\n",
    "\n",
    "                    for i in range(len(vectors[0])):\n",
    "                        for j in range(len(vectors[1])):\n",
    "                            if all_mats['itermax'][i, j] > 0:\n",
    "                                aligns['itermax'].add((l1_b2w_map[i], l2_b2w_map[j]))\n",
    "                \n",
    "                    aligns['itermax'] = sorted(aligns['itermax']) ## word pairs\n",
    "                                        \n",
    "                    for index_to_project in indexes_to_project: ## for each index to project\n",
    "                        \n",
    "                        projection = 0\n",
    "                        label_to_project = flair_annotation[index_to_project]\n",
    "                        ent_loc_id = loc_ent_ids[index_to_project]\n",
    "                        topostext_id = topostext_ids[index_to_project]\n",
    "                        \n",
    "                        ## project the LOC ids\n",
    "                        \n",
    "                        for wordpair in aligns['itermax']: ## for each word alignment in the sentences\n",
    "                            i_engword = int(wordpair[0]) ## get the index of the eng word\n",
    "                            if index_to_project == i_engword: ## if the index was aligned\n",
    "                                i_latword = int(wordpair[1]) ## get the index of the lat word\n",
    "                                \n",
    "                                NH_lat_sentences['loc_ent_id'][indexes_to_update[i_latword]] = ent_loc_id ## indexes_to_update[i_latword] gets the index of the token in the NH_lat_sentences dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2f689",
   "metadata": {},
   "source": [
    "Assign the IOB labels B-LOC and I-LOC to the Latin tokens containing the projected loc_ent_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "NH_lat_loc_ent =  NH_lat_sentences[NH_lat_sentences['loc_ent_id'] != '-'] ## select all the LOC tokens\n",
    "NH_lat_loc_ent.reset_index()\n",
    "max_value = NH_lat_loc_ent['loc_ent_id'].max() ## get the maximum numeric value of the loc ids\n",
    "\n",
    "for n in range(0, max_value+1): ## for each loc_ent_id\n",
    "    \n",
    "    filter_loc_ent = NH_lat_loc_ent[NH_lat_loc_ent['loc_ent_id'] == n] ## select all the tokens with the same loc_ent_id\n",
    "    filter_loc_ent.reset_index(inplace=True)\n",
    "    for i,flair_ner in enumerate(filter_loc_ent['flair_ner']): ## for each token\n",
    "        index_to_update = filter_loc_ent['level_0'][i]\n",
    "        if i == 0: ## for the first token\n",
    "            NH_lat_sentences['flair_ner'][index_to_update] = 'B-LOC' ## assign B-LOC\n",
    "        else : NH_lat_sentences['flair_ner'][index_to_update] = 'I-LOC' ## assign I-LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9903af",
   "metadata": {},
   "outputs": [],
   "source": [
    "NH_lat_sentences.to_csv('data/intermediate/NH_lat_projected.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
